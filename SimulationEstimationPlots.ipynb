{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize_scalar  \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd \n",
    "import statistics as stats\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.dates as mdates\n",
    "import mpmath\n",
    "from scipy.integrate import quad \n",
    "import scipy.optimize as optimize\n",
    "import time\n",
    "from fbm import FBM\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import gamma\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import moment \n",
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.seed(10)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "n = 6 #must be an integer \n",
    "N = T*n\n",
    "delta = T/N \n",
    "steps = N\n",
    "r = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Real data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\n",
    "     os.path.join(\"realisedvariancesourceredclosingprice.xlsx\"),\n",
    "     engine='openpyxl',\n",
    ")\n",
    "list_dates_formated = []\n",
    "list_dates = list(data['Unnamed: 0'])\n",
    "list_names = list(data['Symbol'])\n",
    "list_closing_prices= list(data['close_price'])\n",
    "A_all = []\n",
    "size_current = len(list_dates)\n",
    "for i in range(0,size_current):\n",
    "    date = list_dates[i].split(\" \")[0].split(\"-\")\n",
    "    year = int(date[0])\n",
    "    month = int(date[1])\n",
    "    day = int(date[2])    \n",
    "    list_dates_formated.append(dt.datetime(year,month,day))\n",
    "    A_all.append([dt.datetime(year,month,day),list_names[i],list_closing_prices[i]])\n",
    "df_all_returns = pd.DataFrame(A_all)\n",
    "df_all_returns.columns = [\"Date\",\"Names\",\"close_price\"]      \n",
    "\n",
    "\n",
    "def returns_real_data(index,start_date,end_date):\n",
    "    Prices = df_all_returns.iloc[list(df_all_returns['Names'] == list_names_unique[index])]\n",
    "    True_False = []\n",
    "    Dates_between = list(Prices['Date'] )\n",
    "    for date in Dates_between:\n",
    "        if start_date <= date <= end_date:\n",
    "            True_False.append(True)\n",
    "        else: \n",
    "            True_False.append(False)\n",
    "    #take the range of date we are interested in \n",
    "    Prices_df = Prices.iloc[True_False]\n",
    "    Prices_df.dropna(axis=1)\n",
    "    Prices_list = list(Prices_df['close_price'])\n",
    "    Returns_list = []\n",
    "    for i in range(len(Prices_list)-1):\n",
    "        Returns_list += [np.log(Prices_list[i+1]/Prices_list[i])]\n",
    "    return(Returns_list)\n",
    "\n",
    "def prices_real_data(index,start_date,end_date): #for jump diffusion process\n",
    "    Prices = df_all_returns.iloc[list(df_all_returns['Names'] == list_names_unique[index])]\n",
    "    True_False = []\n",
    "    Dates_between = list(Prices['Date'] )\n",
    "    for date in Dates_between:\n",
    "        if start_date <= date <= end_date:\n",
    "            True_False.append(True)\n",
    "        else: \n",
    "            True_False.append(False)\n",
    "    #take the range of date we are interested in \n",
    "    Prices_df = Prices.iloc[True_False]\n",
    "    Prices_df.dropna(axis=1)\n",
    "    Prices_list = list(Prices_df['close_price'])\n",
    "    return(Prices_list)\n",
    "\n",
    "list_names_unique = sorted(list(set(list(df_all_returns['Names']))))\n",
    "\n",
    "data = pd.read_excel(\n",
    "     os.path.join(\"realisedvariancesourcered.xlsx\"),#with closing prices to generate from the same model\n",
    "     engine='openpyxl',\n",
    ")\n",
    "data.describe()\n",
    "list_dates_formated = []\n",
    "list_dates = list(data['Unnamed: 0'])\n",
    "list_names = list(data['Symbol'])\n",
    "list_RV_5min = list(data['rv5'])\n",
    "list_n = list(data['nobs'])\n",
    "A_all = []\n",
    "size_current = len(list_dates)\n",
    "for i in range(0,size_current):\n",
    "    date = list_dates[i].split(\" \")[0].split(\"-\")\n",
    "    year = int(date[0])\n",
    "    month = int(date[1])\n",
    "    day = int(date[2])    \n",
    "    list_dates_formated.append(dt.datetime(year,month,day))\n",
    "    A_all.append([dt.datetime(year,month,day),list_names[i],list_RV_5min[i],list_n[i]])\n",
    "df_all = pd.DataFrame(A_all)\n",
    "df_all.columns = [\"Date\",\"Names\",\"RV_5min\",\"n\"]      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jump Diffusion model - Simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merton_jump_paths(S, T, r, sigma,  lam, m, v, steps, Npaths):\n",
    "    size=(steps,Npaths)\n",
    "    delta = T/steps/365 \n",
    "    poi_rv = np.multiply(np.random.poisson( lam*delta, size=size),\n",
    "                         np.random.normal(m,v, size=size)).cumsum(axis=0)\n",
    "    geo = np.cumsum(((r -  sigma**2/2 -lam*(m  + v**2*0.5))*delta +\\\n",
    "                              sigma*np.sqrt(delta) * \\\n",
    "                              np.random.normal(size=size)), axis=0)\n",
    "    \n",
    "    return 100*np.exp(geo+poi_rv)\n",
    "\n",
    "def returns_merton_jump_paths(generated_path):\n",
    "    generated_path_prices = [100]\n",
    "    generated_path_returns = []\n",
    "    n = int(steps/T)\n",
    "    for i in range(T):\n",
    "        generated_path_prices += [generated_path[i*n][0]]\n",
    "        generated_path_returns += [math.copysign(1, np.log(generated_path_prices[i+1]/generated_path_prices[i]))*min(abs(np.log(generated_path_prices[i+1]/generated_path_prices[i])),0.2)]\n",
    "    return(generated_path_returns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Heston model - Simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeMC (params):\n",
    "    mu, v0, rho, kappa, theta, xi = params[0],  params[1],  params[2],  params[3],  params[4],  params[5]\n",
    "    # Generate a Monte Carlo simulation for the Heston model\n",
    "    S0 = 100\n",
    "    # Generate random Brownian Motion\n",
    "    MU  = np.array([0, 0])\n",
    "    COV = np.matrix([[1, rho], [rho, 1]])\n",
    "    W   = np.random.multivariate_normal(MU, COV, T)\n",
    "    W_S = W[:,0]\n",
    "    W_v = W[:,1]\n",
    "    delta = 1/365 #365 days in a year \n",
    "    # Generate paths\n",
    "    vt    = np.zeros(T)\n",
    "    vt[0] = v0\n",
    "    St    = np.zeros(T)\n",
    "    St[0] = S0\n",
    "    rt    = np.zeros(T-1)\n",
    "    for t in range(1,T):\n",
    "        vt[t] = max(np.abs(vt[t-1] + kappa*(theta-np.abs(vt[t-1]))*delta + xi*np.sqrt(np.abs(vt[t-1]))*W_v[t]*np.sqrt(delta)),0.0001)\n",
    "        St[t] = St[t-1]*np.exp((mu - 0.5*vt[t-1])*delta + np.sqrt(vt[t-1]*delta)*W_S[t])\n",
    "        rt[t-1] =math.copysign(1,mu - 0.5*vt[t-1]*delta + np.sqrt(vt[t-1]*delta)*W_S[t])*min(abs(mu - 0.5*vt[t-1]*delta + np.sqrt(vt[t-1]*delta)*W_S[t]),0.5)\n",
    "\n",
    "    return rt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rough Heston model - Simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_Heston(params,r_abs_max = 0.5,T = T, N = N):\n",
    "    n = N/T*365 #to convert T in years\n",
    "    rho, Lambda, theta,nu, H, v0 = params[0], params[1], params[2], params[3], params[4], params[5]\n",
    "    # Generate random Brownian Motion\n",
    "    MU  = np.array([0, 0])\n",
    "    COV = np.matrix([[1, rho], [rho, 1]])\n",
    "    W   = np.random.multivariate_normal(MU, COV, N+1)\n",
    "    W_S = W[:,0]\n",
    "    W_v = W[:,1]\n",
    "    # Generate paths\n",
    "    var = np.zeros(N+1)\n",
    "    var[0] = v0\n",
    "    rt    = np.zeros(N)\n",
    "    r_list = []\n",
    "    sigma_list = []\n",
    "    r = 0 \n",
    "    for i in range(1,N):\n",
    "        SUM1 = 0\n",
    "        SUM2 = 0\n",
    "        for j in range(1,i):\n",
    "            SUM1 += 1/(H+0.5)*(theta - var[j])*(-(i/(n) - j/n)**(H+0.5)+(i/n - (j +1)/n)**(H+0.5))\n",
    "            SUM2 += ((i/n - (j-0.5)/n)**(H-0.5))*np.sqrt(var[j])*(W_v[j+1]-W_v[j])*np.sqrt(1/n)\n",
    "        var[i+1] = abs(v0 + Lambda/float(gamma(H+0.5))*SUM1+nu/float(gamma(H+0.5))*SUM2)\n",
    "        rt[i] = np.sqrt(var[i+1])*W_S[i+1]*np.sqrt(1/n)\n",
    "        r += rt[i]\n",
    "        if (i%int(n/365) == 0):\n",
    "            r = math.copysign(min(r_abs_max,abs(r)),r)\n",
    "            r_list.append(r)\n",
    "            r = 0 \n",
    "            sigma_list.append(np.sqrt(var[i+1]))\n",
    "    return(r_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rough fSV model - Simulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_r_generator_opt(nu,Lambda,ksi,H,fbm_sample):\n",
    "    Var_Y_t = (nu**2)/(2*Lambda**(2*H))*float(gamma(1+2*H))\n",
    "    eta = np.log(ksi) - 0.5*Var_Y_t\n",
    "    Y0 = norm.rvs(loc=eta, scale=1, size=1)\n",
    "    Y_list = [Y0]\n",
    "    Y = Y0\n",
    "    Delta = T/N/365 \n",
    "    n = 1/Delta\n",
    "    for i in range(0,N):\n",
    "        Y = eta + (Y - eta)*np.exp(-Lambda*Delta)+nu*np.exp(-Lambda*Delta/2)*(fbm_sample[i+1]-fbm_sample[i])\n",
    "        Y_list.append(Y)\n",
    "    sigma_list = []\n",
    "    r_list = []\n",
    "    I_list = []#list of increments\n",
    "    r = 0\n",
    "    for i in range(0,N):\n",
    "        sigma = np.sqrt(np.exp(Y_list[i])) \n",
    "        I = np.random.randn(1)[0]*np.sqrt(1/n)\n",
    "        I_list.append(I)\n",
    "        r += sigma[0]*I\n",
    "        if (i%int(n/365) == 0):\n",
    "            r_list.append(r)\n",
    "            r = 0 \n",
    "            sigma_list.append(sigma[0])\n",
    "    return(r_list)\n",
    "\n",
    "def data_S_generator_opt(X):\n",
    "    l = len(X)\n",
    "    S = [100]\n",
    "    s = 100\n",
    "    for i in range(l):\n",
    "        s = s*(1+X[i])\n",
    "        S.append(s)\n",
    "    return(S)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tools for parameters estimation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random datetime between `start` and `end`\"\"\"\n",
    "    return start + dt.timedelta(\n",
    "        # Get a random amount of seconds between `start` and `end`\n",
    "        seconds=rd.randint(0, int((end - start).total_seconds())),\n",
    "    )\n",
    "\n",
    "N_iteration = 50\n",
    "Number = 20\n",
    "Number_Heston = 10\n",
    "N_iteration_Rough_Heston = 10\n",
    "N_iteration_Rough_fSV = 10\n",
    "N_iteration_Heston = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Jump Diffusion model - Estimation parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=0.02\n",
    "def TS_mean(params): \n",
    "    sigma,  lam, m, v = params[0], params[1], params[2], params[3]\n",
    "    y = r - (sigma**2)/2-lam*(np.exp(m+0.5*(v**2))-1)+lam*m\n",
    "    return(y)\n",
    "\n",
    "def TS_var(params):\n",
    "    sigma,  lam, m, v = params[0], params[1], params[2], params[3]\n",
    "    y = (sigma**2) + lam*(v**2)+ lam*(m**2)\n",
    "    return(y)\n",
    "\n",
    "def TS_skew(params):\n",
    "    sigma,  lam, m, v = params[0], params[1], params[2], params[3]\n",
    "    y =(lam*(3*(v**2)*m+m**3))/((((sigma**2) + lam*(v**2)+ lam*(m**2)))**1.5)\n",
    "    return(y)\n",
    "\n",
    "def TS_kurt(params):\n",
    "    sigma,  lam, m, v = params[0], params[1], params[2], params[3]\n",
    "    y = (lam*(3*(v**4)+6*(v**2)*(m**2)+m**4))/((((sigma**2) + lam*(v**2)+ lam*(m**2)))**2)\n",
    "    return(y)\n",
    "\n",
    "def optim(params_real):\n",
    "    mean_real, var_real, skew_real, kurt_real = params_real[0], params_real[1], params_real[2], params_real[3]\n",
    "    def f(params):\n",
    "        y = 2*abs(TS_mean(params)-mean_real)+2*abs(TS_var(params)-var_real)+abs(TS_skew(params)-skew_real)+abs(TS_kurt(params)-kurt_real)\n",
    "        return(y)\n",
    "    sigma0 = rd.uniform(0.02,0.1)\n",
    "    lam0 = rd.uniform(0.0001,1)\n",
    "    m0 = rd.uniform(-1,1)\n",
    "    v0 =  rd.uniform(0.02,0.5)\n",
    "    params0 = np.array([sigma0,lam0,m0,v0]) \n",
    "    res = optimize.minimize(f, params0, tol=1e-1,bounds = [(-5,5),(0,5),(-5,5),(0,5)])\n",
    "    params_opt = res.x \n",
    "    return(params_opt)\n",
    "\n",
    "def Jump_Diffusion_parameters_estimation(N_iteration,index):\n",
    "    print(list_names_unique[index])\n",
    "    params_fitted = np.array([0,0,0,0],dtype = float)\n",
    "    for i in range(N_iteration):\n",
    "        TIME = 2*T\n",
    "        end_date = dt.datetime(2020,1,1) - dt.timedelta(TIME)\n",
    "        start_date = random_date(dt.datetime(2000,1,1),end_date)\n",
    "        end_date = start_date + dt.timedelta(TIME)\n",
    "        end_date_final = random_date(end_date,dt.datetime(2021,1,1))\n",
    "        prices = prices_real_data(index,start_date,end_date_final)\n",
    "        prices_mean = np.mean(prices)\n",
    "        prices_var = np.var(prices)\n",
    "        prices_skew = skew(prices)\n",
    "        prices_kurt = kurtosis(prices)\n",
    "        params_real = np.array([prices_mean,prices_var,prices_skew,prices_kurt])\n",
    "        params_fitted += optim(params_real)\n",
    "    params_fitted = params_fitted/N_iteration\n",
    "    return(params_fitted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Heston model - Estimation parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments_1(returns_list):\n",
    "    return(stats.mean(returns_list))\n",
    "\n",
    "def moments_2(returns_list):\n",
    "    return(stats.variance(returns_list))\n",
    "\n",
    "def moments_3(returns_list):\n",
    "    return(skew(returns_list))\n",
    "\n",
    "def moments_4(returns_list):\n",
    "    return(kurtosis(returns_list))\n",
    "\n",
    "def moments_5(returns_list):\n",
    "    return(moment(returns_list,5))\n",
    "\n",
    "def moments_6(returns_list):\n",
    "    return(moment(returns_list,6))\n",
    "\n",
    "def moment_vectors(returns_list):\n",
    "    M1 = moments_1(returns_list)\n",
    "    M2 = moments_2(returns_list)\n",
    "    M3 = moments_3(returns_list)\n",
    "    M4 = moments_4(returns_list)\n",
    "    M5 = moments_5(returns_list)\n",
    "    M6 = moments_6(returns_list)\n",
    "    return([M1,M2,M3,M4,M5,M6])\n",
    "\n",
    "def N_simulations_moments_Heston(Number,params, T =T, N=N):\n",
    "    moments = np.array([[0]*6]*Number, dtype=float)\n",
    "    for i in range(Number):\n",
    "        returns_list = HeMC(params)\n",
    "        M = moment_vectors(returns_list)\n",
    "        moments[i,] = M\n",
    "    return(moments)\n",
    "\n",
    "def global_loss_L1_Heston(params,index,Number = Number_Heston):\n",
    "    sim_moments = N_simulations_moments_Heston(Number,params)\n",
    "    n_sim_returns = sim_moments.shape[0]#number of lines\n",
    "    n_moments = sim_moments.shape[1] \n",
    "    moments_losses = np.array([[0]*6]*n_sim_returns, dtype=float)\n",
    "    for i in range(n_sim_returns):\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2021,1,1))\n",
    "        TIME = 2*T\n",
    "        end_date = start_date + dt.timedelta(TIME)\n",
    "        returns = returns_real_data(index,start_date,end_date)\n",
    "        real_moment = moment_vectors(returns)\n",
    "        for j in range(n_moments):\n",
    "            moments_losses[i,j] = abs(sim_moments[i,j]-real_moment[j])\n",
    "    vector_losses = np.mean(moments_losses, axis=0)\n",
    "    vector_losses_norm = np.array([0]*n_moments, dtype=float)\n",
    "    for j in range(n_moments):\n",
    "        vector_losses_norm[j] = vector_losses[j]/np.max(moments_losses[:,j])#could have scaled with the sum\n",
    "    mean_losses_norm = np.mean(vector_losses_norm)\n",
    "    mean_losses = np.mean(vector_losses)\n",
    "    return(mean_losses_norm)\n",
    "\n",
    "def Heston_parameters_estimation(N_iteration_Heston,index):\n",
    "    print(list_names_unique[index])\n",
    "    params_fitted = 0\n",
    "    for i in range(N_iteration_Heston): \n",
    "        mu, v0, rho, kappa, theta, xi = rd.uniform(0.02,0.2),rd.uniform(0.01,0.5), rd.uniform(-0.7,0.1), rd.uniform(0.1,0.5), rd.uniform(0.05,0.4), rd.uniform(0.1,0.35)\n",
    "        x0 = np.array([mu, v0, rho, kappa, theta, xi],dtype = float)\n",
    "        res = optimize.minimize(global_loss_L1_Heston,x0,args=(index,Number),method = \"powell\", bounds = [(0.00001,2),(0.0001,1),(-1,1),(0.000001,10),(0.0001,10),(0.000001,10)])\n",
    "        params_fitted += res.x\n",
    "    params_fitted = params_fitted/N_iteration_Heston\n",
    "    return(params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rough Heston model - Estimation parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moments_1(returns_list):\n",
    "    return(stats.mean(returns_list))\n",
    "\n",
    "def moments_2(returns_list):\n",
    "    return(stats.variance(returns_list))\n",
    "\n",
    "def moments_3(returns_list):\n",
    "    return(skew(returns_list))\n",
    "\n",
    "def moments_4(returns_list):\n",
    "    return(kurtosis(returns_list))\n",
    "\n",
    "def moments_5(returns_list):\n",
    "    return(moment(returns_list,5))\n",
    "\n",
    "def moments_6(returns_list):\n",
    "    return(moment(returns_list,6))\n",
    "\n",
    "def moment_vectors(returns_list):\n",
    "    M1 = moments_1(returns_list)\n",
    "    M2 = moments_2(returns_list)\n",
    "    M3 = moments_3(returns_list)\n",
    "    M4 = moments_4(returns_list)\n",
    "    M5 = moments_5(returns_list)\n",
    "    M6 = moments_6(returns_list)\n",
    "    return([M1,M2,M3,M4,M5,M6])\n",
    "\n",
    "def N_simulations_moments(Number,params, T =T, N=N):\n",
    "    moments = np.array([[0]*6]*Number, dtype=float)\n",
    "    for i in range(Number):\n",
    "        returns_list = simulation_Heston(params,0.5,T , N )\n",
    "        M = moment_vectors(returns_list)\n",
    "        moments[i,] = M\n",
    "    return(moments)\n",
    "\n",
    "def global_loss_L1(params,index,Number = Number,T =T, N=N):\n",
    "    sim_moments = N_simulations_moments(Number,params,T,N)\n",
    "    n_sim_returns = sim_moments.shape[0]#number of lines\n",
    "    n_moments = sim_moments.shape[1] \n",
    "    moments_losses = np.array([[0]*6]*n_sim_returns, dtype=float)\n",
    "    for i in range(n_sim_returns):\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2021,1,1))\n",
    "        TIME = 2*T\n",
    "        end_date = start_date + dt.timedelta(TIME)\n",
    "        returns = returns_real_data(index,start_date,end_date)\n",
    "        real_moment = moment_vectors(returns)\n",
    "        for j in range(n_moments):\n",
    "            moments_losses[i,j] = abs(sim_moments[i,j]-real_moment[j])\n",
    "    vector_losses = np.mean(moments_losses, axis=0)\n",
    "    vector_losses_norm = np.array([0]*n_moments, dtype=float)\n",
    "    for j in range(n_moments):\n",
    "        vector_losses_norm[j] = vector_losses[j]/np.max(moments_losses[:,j])#could have scaled with the sum\n",
    "    mean_losses_norm = np.mean(vector_losses_norm)\n",
    "    mean_losses = np.mean(vector_losses)\n",
    "    return(mean_losses_norm)\n",
    "\n",
    "\n",
    "\n",
    "def Rough_Heston_parameters_estimation(N_iteration_Rough_Heston,index):\n",
    "    print(list_names_unique[index])\n",
    "    params_fitted = 0\n",
    "    for i in range(N_iteration_Rough_Heston):\n",
    "        v0, rho, Lambda, theta,nu, H = rd.uniform(0.02,0.2),rd.uniform(-0.7,0.1), rd.uniform(0.3,1), rd.uniform(0.02,0.2), rd.uniform(0.1,0.5), rd.uniform(0.05,0.25)\n",
    "        x0 = np.array([rho, Lambda, theta,nu, H, v0],dtype = float)\n",
    "        res = optimize.minimize(global_loss_L1,x0,args=(index,Number),method = \"powell\", bounds = [(-1,1),(0.001,10),(0,2),(-10,10),(0,0.5),(0,2)])\n",
    "        params_fitted += res.x\n",
    "    params_fitted = params_fitted/N_iteration_Rough_Heston\n",
    "    return(params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rough fSV model - Estimation parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RV_5min_list(index,start_date,end_date):\n",
    "    RV = df_all.iloc[list(df_all['Names'] == list_names_unique[index])]\n",
    "    True_False = []\n",
    "    Dates_between = list(RV['Date'] )\n",
    "    for date in Dates_between:\n",
    "        if start_date <= date <= end_date:\n",
    "            True_False.append(True)\n",
    "        else: \n",
    "            True_False.append(False)\n",
    "    RV_df = RV.iloc[True_False]\n",
    "    RV_df.dropna(axis=1)\n",
    "    RV_list = list(RV_df['RV_5min'])\n",
    "    n = int(RV_df['n'].mean())\n",
    "    return(RV_list,n)\n",
    "\n",
    "def Kappa(l,xi,Lambda,nu,H):\n",
    "    kappa0 = nu**2/(2*(Lambda**(2*H)))*float(gamma(1+2*H))\n",
    "    if l == 0:\n",
    "        y = kappa0\n",
    "    else:\n",
    "        y = kappa0*math.cosh(Lambda*l)-(nu**2)*(abs(l)**(2*H))/2*mpmath.hyp1f2(1,H+0.5,H+1,(Lambda**2)*(l**2)/4) \n",
    "    return(float(y))\n",
    "\n",
    "def G(l,xi,Lambda,nu,H):\n",
    "    C = (nu**2)/((2*H+1)*(2*H+2))\n",
    "    if l == 0:\n",
    "        y = (xi**2)*np.exp(Kappa(0,xi,Lambda,nu,H))*(1-Kappa(0,xi,Lambda,nu,H)+2*Kappa(0,xi,Lambda,nu,H)/(Lambda**2)*(math.cosh(Lambda)-1)- C*mpmath.hyp1f2(1,H+1.5,H+2,(Lambda**2)/4))\n",
    "    else:\n",
    "         y = (xi**2)*np.exp(Kappa(l,xi,Lambda,nu,H))*(1-Kappa(l,xi,Lambda,nu,H)+2*Kappa(0,xi,Lambda,nu,H)/(Lambda**2)*math.cosh(Lambda*l)*(math.cosh(Lambda)-1)\n",
    "                                                    - (xi**2)*np.exp(Kappa(l,xi,Lambda,nu,H))*C/2*((l+1)**(2*H+2))*mpmath.hyp1f2(1,H+1.5,H+2,(Lambda**2)*((l+1)**2)/4)\n",
    "                                                    -(xi**2)*np.exp(Kappa(l,xi,Lambda,nu,H))*C/2*((l-1)**(2*H+2))*mpmath.hyp1f2(1,H+1.5,H+2,(Lambda**2)*((l-1)**2)/4)\n",
    "                                                    + (xi**2)*np.exp(Kappa(l,xi,Lambda,nu,H))*C*(l**(2*H+2))*mpmath.hyp1f2(1,H+1.5,H+2,(Lambda**2)*(l**2)/4))   \n",
    "    return(float(y))\n",
    "\n",
    "def c(xi,Lambda,nu,H,n):#function of function\n",
    "    def to_integrate(u):\n",
    "        y = (1-u)*np.exp(Kappa(u/n,xi,Lambda,nu,H))\n",
    "        return(y)\n",
    "    y = 4*(xi**2)/n*quad(to_integrate,0,1)[0]\n",
    "    return(y)\n",
    "\n",
    "def gc(l,xi,Lambda,nu,H,n):\n",
    "    if l == 2:\n",
    "        y = G(l,xi,Lambda,nu,H) + c(xi,Lambda,nu,H,n)\n",
    "    else:\n",
    "        y = G(l,xi,Lambda,nu,H)\n",
    "    return(y)\n",
    "\n",
    "def Gc_vector(k,xi,Lambda,nu,H,n):\n",
    "    L = [xi]\n",
    "    for i in range(0,k+1):\n",
    "        L.append(gc(i,xi,Lambda,nu,H,n))\n",
    "    y = np.array(L,dtype=float)\n",
    "    y = np.reshape(y,(k+2,1))\n",
    "    return(y)\n",
    "\n",
    "def hat_IV_vector(t,RV_list,n,k):\n",
    "    L = [RV_list[t-1]]*min(k+2,t+2)+[0]*max((k-t),0)\n",
    "    a = np.array(L,dtype=float)\n",
    "    LB = [1,RV_list[t-1]]\n",
    "    u = t - 1\n",
    "    i = 1\n",
    "    while (i != 5):\n",
    "        if (u != 0):\n",
    "            u = u - 1 \n",
    "            i +=1 \n",
    "            LB.append(RV_list[u]) \n",
    "        else:\n",
    "            i = 5\n",
    "    b = np.array(LB+[0]*max((k-t+1),0),dtype=float)\n",
    "    y = a*b \n",
    "    y = np.reshape(y,(k+2,1))\n",
    "    return(y)\n",
    "\n",
    "def hat_m(xi,Lambda,nu,H,RV_list,n,k):\n",
    "    T = len(RV_list)\n",
    "    y = np.reshape(np.array((k+2)*[0],dtype=float),(k+2,1))\n",
    "    for i in range(1,T):\n",
    "        y = y + hat_IV_vector(i,RV_list,n,k)\n",
    "    y = y/T\n",
    "    y = y - Gc_vector(k,xi,Lambda,nu,H,n)\n",
    "    return(y)\n",
    "\n",
    "def function_to_min(theta,RV_list,n,k):\n",
    "    xi,Lambda,nu,H = theta[0],theta[1],theta[2],theta[3]\n",
    "    T = len(RV_list)\n",
    "    Product = np.reshape(hat_m(xi,Lambda,nu,H,RV_list,n,k),(1,k+2)).dot(np.eye(k+2)).dot(np.reshape(hat_m(xi,Lambda,nu,H,RV_list,n,k),(k+2,1)))\n",
    "    return(Product[0][0])\n",
    "\n",
    "def hat_theta_one(initial_guess,RV_list,n,k=4,B=[(0.00001,0.1),(0.000001,0.001),(0.001,4),(0.01,0.5)]):\n",
    "    res = optimize.minimize(function_to_min,initial_guess,args =(RV_list,n,k),bounds=B)\n",
    "    if res.success:\n",
    "        fitted_params = res.x\n",
    "        return(fitted_params)\n",
    "    else:\n",
    "        print('error')#raise ValueError()\n",
    "        \n",
    "def W_hat(theta,RV_list,n,k):\n",
    "    xi,Lambda,nu,H = theta[0],theta[1],theta[2],theta[3]\n",
    "    T = len(RV_list)\n",
    "    y = np.array([(k+2)*[0]]*(k+2),dtype=float)\n",
    "    for i in range(1,T+1): \n",
    "        y = y + np.reshape(hat_IV_vector(i,RV_list,n,k)- T*Gc_vector(k,xi,Lambda,nu,H,n),(k+2,1)).dot(np.reshape(hat_IV_vector(i,RV_list,n,k)- T*Gc_vector(k,xi,Lambda,nu,H,n),(1,k+2))) \n",
    "    y = y/T\n",
    "    y = np.linalg.inv(y)\n",
    "    return(y)\n",
    "\n",
    "def function_to_min_2(theta,W,RV_list,n,k=4):\n",
    "    xi,Lambda,nu,H = theta[0],theta[1],theta[2],theta[3]\n",
    "    T = len(RV_list)\n",
    "    Product = np.reshape(hat_m(xi,Lambda,nu,H,RV_list,n,k),(1,k+2)).dot(W).dot(np.reshape(hat_m(xi,Lambda,nu,H,RV_list,n,k),(k+2,1)))#T c'est le k \n",
    "    return(Product[0][0])\n",
    "\n",
    "def hat_theta_two(initial_guess,theta_fitted1,RV_list,n,k=4,B=[(0.00001,0.1),(0.000001,0.001),(0.001,4),(0.01,0.5)]):\n",
    "    W = W_hat(theta_fitted1,RV_list,n,k)\n",
    "    res = optimize.minimize(function_to_min_2,initial_guess,args =(W,RV_list,n,k),bounds=B)\n",
    "    if res.success:\n",
    "        fitted_params = res.x\n",
    "        return(fitted_params)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "\n",
    "def globalizer(i,theta0 = [0.2,0.0004,1,0.08],k=4,B=[(0.000001,1),(0.0000001,0.01),(0.0001,4),(0.005,0.5)]):\n",
    "    start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2021,1,1))\n",
    "    end_date = random_date(start_date,dt.datetime(2021,1,2))\n",
    "    RV_list, n = create_RV_5min_list(i,start_date,end_date)\n",
    "    fitted_1 = hat_theta_one(theta0,RV_list,n,k,B)\n",
    "    print('$hat{theta_{1}}=$',fitted_1)\n",
    "    #fitted_2 = hat_theta_two(fitted_1,fitted_1,RV_list,n,k,B)\n",
    "    #print('$hat{theta_{2}}=$',fitted_2)\n",
    "    return(fitted_1)\n",
    "\n",
    "def Rough_fSV_parameters_estimation(N_iteration_Rough_fSV,index):\n",
    "    print(list_names_unique[index])\n",
    "    params_fitted = 0\n",
    "    for i in range(N_iteration_Rough_fSV):\n",
    "        xi,Lambda,nu,H = rd.uniform(0.001,0.3),rd.uniform(0.0004,0.001),rd.uniform(0.1,2),rd.uniform(0.04,0.15)\n",
    "        theta0 = [xi,Lambda,nu,H]\n",
    "        res = globalizer(index,theta0 ,4,[(0.000001,1),(0.0000001,0.2),(0.00001,4),(0.0005,0.5)])\n",
    "        params_fitted += res\n",
    "    params_fitted = params_fitted/N_iteration_Rough_fSV\n",
    "    return(params_fitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameters estimation for the 4 models__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comparison - Loss function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_Jump_Diffusion(index,N_simulation):\n",
    "    Jump_Diffusion_parameters = Jump_Diffusion_parameters_estimation(N_iteration,index)\n",
    "    sigma,  lam, m, v = Jump_Diffusion_parameters\n",
    "    L_Jump_Diffusion = 0\n",
    "    L = 0\n",
    "    for i in range(N_simulation): \n",
    "        Jump_Diffusion_returns = returns_merton_jump_paths(merton_jump_paths(100, T, 0.02, sigma,  lam, m, v, N, 1))\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2020,1,1))\n",
    "        TIME = 3*T\n",
    "        end_date = start_date + dt.timedelta(days = TIME)\n",
    "        Real_returns = returns_real_data(index,start_date,end_date)\n",
    "        Jump_Diffusion_prices = data_S_generator_opt(Jump_Diffusion_returns)\n",
    "        Real_prices = data_S_generator_opt(Real_returns)\n",
    "        for j in range(T):\n",
    "            L_Jump_Diffusion += abs((Real_prices[j] - Jump_Diffusion_prices[j]))\n",
    "        L_Jump_Diffusion = L_Jump_Diffusion/T\n",
    "        L +=  L_Jump_Diffusion\n",
    "        L_Jump_Diffusion = 0\n",
    "    L = L/N_simulation\n",
    "    print(\"The parameters of the Jump Diffusion model for the equity \"+str(list_names_unique[index])+\" are (\"\n",
    "          +str(Jump_Diffusion_parameters[0])+\",\"+str(Jump_Diffusion_parameters[1])+\",\"+str(Jump_Diffusion_parameters[2])\n",
    "          +\",\"+str(Jump_Diffusion_parameters[3])+\").\")\n",
    "    return(L)\n",
    "\n",
    "def losses_Heston(index,N_simulation):\n",
    "    Heston_parameters = Heston_parameters_estimation(N_iteration_Heston,index)\n",
    "    L_Heston = 0\n",
    "    L = 0\n",
    "    for i in range(N_simulation): \n",
    "        Heston_returns = HeMC (Heston_parameters)\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2020,1,1))\n",
    "        TIME = 3*T\n",
    "        end_date = start_date + dt.timedelta(days = TIME)\n",
    "        Real_returns = returns_real_data(index,start_date,end_date)\n",
    "        Heston_prices = data_S_generator_opt(Heston_returns)\n",
    "        Real_prices = data_S_generator_opt(Real_returns)\n",
    "        for j in range(T):\n",
    "            L_Heston += abs((Real_prices[j] - Heston_prices[j]))\n",
    "        L_Heston =  L_Heston/T\n",
    "        L += L_Heston\n",
    "        L_Heston = 0\n",
    "    L = L/N_simulation\n",
    "    print(\"The parameters of the Heston model for the equity \"+str(list_names_unique[index])+\" are (\"\n",
    "          +str(Heston_parameters[0])+\",\"+str(Heston_parameters[1])+\",\"+ str(Heston_parameters[2])\n",
    "          +\",\"+str(Heston_parameters[3])+\",\"+str(Heston_parameters[4])+\",\"+str(Heston_parameters[5])\n",
    "          +\").\")\n",
    "    return(L)\n",
    "\n",
    "def losses_Rough_Heston(index,N_simulation):\n",
    "    Rough_Heston_parameters = Rough_Heston_parameters_estimation(N_iteration_Rough_Heston,index)\n",
    "    L_Rough_Heston = 0\n",
    "    L = 0\n",
    "    for i in range(N_simulation): \n",
    "        Rough_Heston_returns = simulation_Heston(Rough_Heston_parameters,r_abs_max = 0.5,T = T, N = N)\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2020,1,1))\n",
    "        TIME = 3*T\n",
    "        end_date = start_date + dt.timedelta(days = TIME)\n",
    "        Real_returns = returns_real_data(index,start_date,end_date)\n",
    "        Rough_Heston_prices = data_S_generator_opt(Rough_Heston_returns)\n",
    "        Real_prices = data_S_generator_opt(Real_returns)\n",
    "        for j in range(T):\n",
    "            L_Rough_Heston += abs((Real_prices[j] - Rough_Heston_prices[j]))\n",
    "        L_Rough_Heston  = L_Rough_Heston/T\n",
    "        L += L_Rough_Heston\n",
    "        L_Rough_Heston = 0\n",
    "    L = L/N_simulation\n",
    "    print(\"The parameters of the Rough Heston model for the equity \"+str(list_names_unique[index])+\" are (\"\n",
    "          +str(Rough_Heston_parameters[0])+\",\"+str(Rough_Heston_parameters[1])+\",\"+str(Rough_Heston_parameters[2])\n",
    "          +\",\"+str(Rough_Heston_parameters[3])+\",\"+str(Rough_Heston_parameters[4])+\",\"+str(Rough_Heston_parameters[5])\n",
    "          +\").\") \n",
    "    return( L)\n",
    "\n",
    "def losses_Rough_fSV(index,N_simulation):\n",
    "    Rough_fSV_parameters = Rough_fSV_parameters_estimation(N_iteration_Rough_fSV,index)\n",
    "    L_Rough_fSV = 0\n",
    "    L = 0\n",
    "    ksi,Lambda,nu,H = Rough_fSV_parameters[0],Rough_fSV_parameters[1],Rough_fSV_parameters[2],Rough_fSV_parameters[3]\n",
    "    for i in range(N_simulation): \n",
    "        f = FBM(n=N, hurst=H, length=T, method='cholesky')\n",
    "        fbm_sample = f.fbm()\n",
    "        Rough_fSV_returns = data_r_generator_opt(nu,Lambda,ksi,H,fbm_sample)\n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2020,1,1))\n",
    "        TIME = 3*T\n",
    "        end_date = start_date + dt.timedelta(days = TIME)\n",
    "        Real_returns = returns_real_data(index,start_date,end_date)\n",
    "        Rough_fSV_prices = data_S_generator_opt(Rough_fSV_returns)\n",
    "        Real_prices = data_S_generator_opt(Real_returns)\n",
    "        for j in range(T):\n",
    "            L_Rough_fSV += abs((Real_prices[j] - Rough_fSV_prices[j]))\n",
    "        L_Rough_fSV  = L_Rough_fSV/T  \n",
    "        L += L_Rough_fSV \n",
    "        L_Rough_fSV  = 0\n",
    "    L = L/N_simulation\n",
    "    print(\"The parameters of the Rough fSV model for the equity \"+str(list_names_unique[index])+\" are (\"\n",
    "          +str(Rough_fSV_parameters[0])+\",\"+str(Rough_fSV_parameters[1])+\",\"+str(Rough_fSV_parameters[2])\n",
    "          +\",\"+str(Rough_fSV_parameters[3])+\").\") \n",
    "    return( L)\n",
    "\n",
    "def losses_constant_initial_prices(index,N_simulation):\n",
    "    L_constant = 0\n",
    "    L = 0\n",
    "    for i in range(N_simulation):  \n",
    "        start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2020,1,1))\n",
    "        TIME = 3*T\n",
    "        end_date = start_date + dt.timedelta(days = TIME)\n",
    "        Real_returns = returns_real_data(index,start_date,end_date)\n",
    "        prices = np.array([100]*(T),dtype=float)\n",
    "        Real_prices = data_S_generator_opt(Real_returns)\n",
    "        for j in range(T):\n",
    "            L_constant += abs((Real_prices[j] - prices[j]))\n",
    "        L_constant  = L_constant/T  \n",
    "        L += L_constant \n",
    "        L_constant  = 0\n",
    "    L = L/N_simulation\n",
    "    return( L)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example of use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= timer()\n",
    "L_AORD_Jump_Diffusion = losses_Jump_Diffusion(1,10) \n",
    "end = timer()\n",
    "\n",
    "print(\"Time taken:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_path_simulations(index,params_JD, params_H, params_RH, params_fSV, T, N):\n",
    "    rT_RH = simulation_Heston(params_RH,r_abs_max = 0.5,T = T, N = N)\n",
    "    nu,Lambda,ksi,H = params_fSV[2], params_fSV[1], params_fSV[0], params_fSV[3]\n",
    "    f = FBM(n=N, hurst=H, length=T, method='cholesky')\n",
    "    fbm_sample = f.fbm()\n",
    "    rT_fSV_10 = data_r_generator_opt(nu,Lambda,ksi,H,fbm_sample)\n",
    "    rT_H = HeMC (params_H)\n",
    "    sigma,  lam, m, v = params_JD[0], params_JD[1], params_JD[2], params_JD[3]\n",
    "    rT_JD =  returns_merton_jump_paths(merton_jump_paths(100, T, 0.02, sigma,  lam, m, v, N, 1))\n",
    "    start_date = random_date(dt.datetime(2000,1,1),dt.datetime(2019,1,1))\n",
    "    TIME = 2*T\n",
    "    end_date = start_date + dt.timedelta(days = TIME)\n",
    "    rT_real = returns_real_data(index,start_date,end_date)\n",
    "    rT_real = rT_real[:len(rT_H)+1]\n",
    "    ST_real =  data_S_generator_opt(rT_real) \n",
    "    ST_H = data_S_generator_opt(rT_H)\n",
    "    ST_fSV_10 = data_S_generator_opt(rT_fSV_10)\n",
    "    ST_RH = data_S_generator_opt(rT_RH)\n",
    "    ST_JD = data_S_generator_opt(rT_JD)\n",
    "    return((rT_real, rT_H, rT_fSV_10, rT_RH, rT_JD),(ST_real, ST_H, ST_fSV_10, ST_RH, ST_JD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_4sims_and_real(R,S,save ='no',name = \"num_index\"):\n",
    "    rT_real, rT_H, rT_fSV_10, rT_RH, rT_JD = R\n",
    "    ST_real, ST_H, ST_fSV_10, ST_RH, ST_JD = S\n",
    "    plt.figure()\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(15, 6)\n",
    "    X = range(T)\n",
    "    ax1.plot(X,ST_real[:T],linewidth=0.8)\n",
    "    ax1.plot(X,ST_fSV_10[:T],linewidth=0.8)\n",
    "    ax1.plot(X,ST_RH[:T],linewidth=0.8)\n",
    "    ax1.plot(X,ST_JD[:T],linewidth=0.8)\n",
    "    ax1.set(xlabel='Number of days elapsed t since the starting date\\n \\n \\n', ylabel='Daily prices '+ r'$S_{t}$',title=\"Plot of the price time series against time\\n with an initial price \"+r\"$S_{0}=100$\")\n",
    "    ax2.plot(rT_real,linewidth=0.4,label ='Real data')\n",
    "    ax2.plot(rT_fSV_10,linewidth=0.4,label ='Rough fSV model')\n",
    "    ax2.plot(rT_RH,linewidth=0.4,label ='Rough Heston model')\n",
    "    ax2.plot(rT_JD,linewidth=0.4,label ='Jump diffusion model')\n",
    "    ax2.set(xlabel='Number of days elapsed t since the starting date \\n \\n \\n', ylabel='Daily returns '+ r'$r_{t}$',title=\"Plot of the return time series against time\" )\n",
    "    leg = fig.legend(frameon=True, loc='lower center', ncol=5)\n",
    "    # get the individual lines inside legend and set line width\n",
    "    for line in leg.get_lines():\n",
    "        line.set_linewidth(4)\n",
    "    if save != 'no':\n",
    "        plt.savefig('Comparison_'+str(name)+'.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example of use__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_JD_SPX = np.array([ 1.2902517051852678,1.9326961807012852,-0.64727243732107,0.37134788480208913])\n",
    "params_H_SPX = np.array([0.8904757261820736,0.5073357551034949,-0.2371919515133079,5.317697836966241,5.27149187746957,4.893097016530513]) \n",
    "params_RH_SPX = np.array([0.06173884810561812,5.81688835552416,0.8585671402167568,-1.1499604689838576,0.24471108690569632,0.9189124895509331]) \n",
    "params_fSV_SPX = np.array([5.394818894781241e-05,0.009999999999999273,0.48141362516206093,0.034625746342434933]) \n",
    "\n",
    "T = 20\n",
    "N = 6*T\n",
    "R_SPX,S_SPX = one_path_simulations(26, params_JD_SPX, params_H_SPX, params_RH_SPX, params_fSV_SPX, T, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_4sims_and_real(R_SPX,S_SPX,save ='no',name = \"num_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Implementation of the Brownian Motion for the classifier (Chapter 3 Thesis)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brownian_motion(N, T, h):\n",
    "    \"\"\"\n",
    "    Simulates a Brownian motion\n",
    "    :param int N : the number of discrete steps\n",
    "    :param int T: the number of continuous time steps\n",
    "    :param float h: the variance of the increments\n",
    "    \"\"\"\n",
    "    dt = 1. * T/N  # the normalizing constant\n",
    "    random_increments = np.random.normal(0.0, 1.0 * h, N)*np.sqrt(dt)  # the epsilon values\n",
    "    brownian_motion = np.cumsum(random_increments)  # calculate the brownian motion\n",
    "    brownian_motion = np.insert(brownian_motion, 0, 0.0) # insert the initial condition\n",
    "\n",
    "    return brownian_motion, random_increments\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
